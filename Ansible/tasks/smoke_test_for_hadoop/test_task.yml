---
# SMOKE TEST FOR HADOOP тестированиввя инсталяции кластера hadoop

- name: SMOKE TEST FOR HADOOP 
  hosts: all
  #remote_user: cloudera
  remote_user: root
  gather_facts: no
  # Поправить названия и переменные 
  vars:
      # ПЕРЕМЕННЫЕ КОТОРЫЕ НЕОБХОДИМО СМЕНТЬ ПОД КОНКРЕТНУЮ КОНФИГУРАЦИЮ КЛАСТЕРА
      # переменные для хоста zookeeper
      var_zookeeper_host: localhost    
      var_zookeeper_port: 2181
      # задание переменной для HIVESERVER2 необходимо указать hostname где запущен HS2 
      var_hiveserver2: localhost
      # задание переменной для IMPALA необходимо указать hostname где запущен Impala Daemon
      var_impala: localhost
      # задание переменной размещения SPARK example
      # /opt/cloudera/parcels/CDH/lib/spark/bin/run-example
      # /usr/lib/spark/examples/lib/spark-examples*.jar
      var_spark: /usr/lib/spark/examples/lib/spark-examples*.jar
      # задание переменной размещения SPARK example
      # /usr/lib/hadoop-mapreduce/hadoop-mapreduce-examples-2.6.0-cdh5.13.0.jar 
      # /opt/cloudera/parcels/CDH-7.1.7-1.cdh7.1.7.p0.15945976/lib/hadoop-mapreduce/hadoop-mapreduce-examples-3.1.1.7.1.7.0-551.jar
      # var_mapreduce: /usr/lib/hadoop-mapreduce/hadoop-mapreduce-examples.jar
      var_mapreduce: /opt/cloudera/parcels/CDH-7.1.7-1.cdh7.1.7.p0.15945976/lib/hadoop-mapreduce/hadoop-mapreduce-examples-3.1.1.7.1.7.0-551.jar
      # ПЕРЕМЕННЫЕ КОТОРЫЕ МОЖНО ОСТАВИТЬ ПО УМОЛЧАНИЮ
      # задание временной папки в локальной системе и в hdfs
      # ВАЖНО если значение будет изменено произвести корректировку путей в файле ./source/test_spark
      var_env_tmp_dir: tmp/smoke_test_for_hadoop
      # задание папки источника 
      var_source_tmp_dir: ./source/
      # задание переменных файлов для тестирования находящихся в папке {{var_source_tmp_dir}}
      var_file_test_zookeeper: test_zookeeper
      var_file_clean_zookeeper: clean_zookeeper
      var_file_test_hbase: test_hbase
      var_file_test_spark: test_spark
      var_file_test_spark_in: test_spark_in
      var_file_clean_hbase: clean_hbase
  tasks:
    # PREPARING FOR SMOKE TESTS 
    - name: PREPARING FOR SMOKE TESTS 
      ansible.builtin.debug:
        msg: THIS BLOCK PREPARING FOR SMOKE TESTS

    # обнуление временной папки
    - name: delete enviroment /{{ var_env_tmp_dir }}
      ansible.builtin.file:
        path: /{{ var_env_tmp_dir }}
        state: absent

    # отчиска временной папки hdfs
    - name: clean HDFS 
      shell: hdfs dfs -rmr /{{ var_env_tmp_dir }}
      ignore_errors: yes

    # cleaning hive table
    - name: cleaning hive table 
      shell:  beeline -u "jdbc:hive2:///{{ var_hiveserver2 }}:10000/" -e 'DROP TABLE default.smoke_test;'  
      register: results
    - debug:
        var: results
      ignore_errors: yes
    # Создание временной папки
    - name: create enviroment /{{ var_env_tmp_dir }}
      ansible.builtin.file:
        path: /{{ var_env_tmp_dir }}
        state: directory  
    # Копирование необходимых файлов во временную директорию 
    - name: COPY FILES TO /{{ var_env_tmp_dir }}
      copy: src={{ var_source_tmp_dir }} dest=/{{ var_env_tmp_dir }}
    # cleaning HBASE
    #- name: cleaning hbase 
    #  shell:  hbase shell -n /{{ var_env_tmp_dir }}/{{ var_file_clean_hbase }}
    #  register: results
    #- debug:
    #    var: results
  
    ############################################################ 
    # INFO ZOOKEEPER TESTING 
    - name: TEST ZOOKEEPER 
      ansible.builtin.debug:
        msg: TEST ZOOKEEPER BEGIN WITH {{ var_zookeeper_host }}:{{ var_zookeeper_port }}
    # TESTING ZOOKEEPER
    - name: testing ZOOKEEPER cat /{{ var_env_tmp_dir }} | zookeeper-client -server {{ var_zookeeper_host }}:{{ var_zookeeper_port }}
      shell: cat /{{ var_env_tmp_dir }}/{ {var_file_test_zookeeper }} | zookeeper-client -server {{ var_zookeeper_host }}:{{ var_zookeeper_port }}
      register: results
    - debug:
        var: results  
    # CLEANING ZOOKEEPER
    - name: cleaning ZOOKEEPER cat /{{ var_file_clean_zookeeper }} | zookeeper-client -server {{ var_zookeeper_host }}:{{ var_zookeeper_port }}
      shell: cat /{{ var_env_tmp_dir }}/{{ var_file_clean_zookeeper }} | zookeeper-client -server {{ var_zookeeper_host }}:{{ var_zookeeper_port }}
      register: results
    - debug:
        var: results

    # INFO HDFS TESTING 
    - name: TEST HDFS 
      ansible.builtin.debug:
        msg: TEST HDFS BEGIN 
    
    # TESTING HDFS
    - name: create dir HDFS 
      shell: hdfs dfs -mkdir -p /{{ var_env_tmp_dir }}
      register: results
    - debug:
        var: results

    - name: testing HDFS 
      shell: hdfs dfs -put /etc/hosts /{{ var_env_tmp_dir }}/hosts && hdfs dfs -get /{{ var_env_tmp_dir }}/hosts /{{ var_env_tmp_dir }}/hosts && cat /{{ var_env_tmp_dir }}/hosts
      register: results
    - debug:
        var: results
    
    # TESTING MAPREDUCE Pi ESTIMATION
    - name: testing MapReduce Pi Estimator 
      shell:  yarn jar {{ var_mapreduce }} pi 10 100  
      register: results
    - debug:
        var: results

    # TESTING HIVE 
    # var_hiveserver2: loclahost
    # Create hive table
    - name: testing hive Create hive table 
      shell:  beeline -u "jdbc:hive2://{{ var_hiveserver2 }}:10000/" -e 'CREATE TABLE default.smoke_test(id INT, name STRING) ROW FORMAT DELIMITED FIELDS TERMINATED BY " " STORED AS TEXTFILE;'  
      register: results
    - debug:
        var: results
    # Insert data
    - name: testing hive Insert data 
      shell:  beeline -u "jdbc:hive2://{{ var_hiveserver2 }}:10000/" -e 'INSERT INTO TABLE default.smoke_test VALUES (1, "justin"), (2, "michael");'
      register: results
    - debug:
        var: results
    # Query hive table
    - name: testing hive Query hive table 
      shell:  beeline -u "jdbc:hive2:///{{ var_hiveserver2 }}:10000/" -e 'SELECT * FROM default.smoke_test WHERE id=1;'  
      register: results
    - debug:
        var: results    

    # TESTING HBASE
    - name: testing hbase 
      shell:  hbase shell -n /{{ var_env_tmp_dir }}/{{ var_file_test_hbase }}
      register: results
    - debug:
        var: results  
    # cleaning HBASE
    - name: cleaning hbase 
      shell:  hbase shell -n /{{ var_env_tmp_dir }}/{{ var_file_clean_hbase }}
      register: results
    - debug:
        var: results

    # TESTING IMPALA
    # требует корректного прохождения теста HIVE, тк использует базу данных созданую в этом тесте 
    # testing impala invalidate metadata 
    - name: testing impala invalidate metadata 
      shell:  impala-shell -i {{ var_impala }} -q "INVALIDATE METADATA default.smoke_test;"
      register: results
    - debug:
        var: results  
    # testing impala select data
    - name: testing impala invalidate metadata 
      shell:  impala-shell -i {{ var_impala }} -q "SELECT * FROM default.smoke_test;"
      register: results
    - debug:
        var: results  
    
    # TESTING SPARK Pi ESTIMATION
    # spark-submit --class org.apache.spark.examples.SparkPi --master yarn --num-executors 1 --driver-memory 512m --executor-memory 512m --executor-cores 1 /opt/cloudera/parcels/CDH-7.1.7-1.cdh7.1.7.p0.15945976/lib/spark/examples/jars/spark-examples_2.11-2.4.7.7.1.7.0-551.jar 10
    #- name: testing Spark Pi Estimation 
    #  shell: spark-submit --class org.apache.spark.examples.SparkPi --master yarn-client --num-executors 1 --driver-memory 512m --executor-memory 512m --executor-cores 1 {{ var_spark }} 10
    #  register: results
    #- debug:
    #    var: results 

    # TESTING SPARK Wordcount
    - name: prepare files on hdfs 
      shell:  hdfs dfs -put /{{ var_env_tmp_dir }}/{{ var_file_test_spark_in }} /{{ var_env_tmp_dir }}/{{ var_file_test_spark_in }}
      register: results
    - debug:
        var: results
    
    - name: execute spark-shell 
      #shell:  cat /{{ var_env_tmp_dir }}/{{ var_file_test_spark }} | spark-shell --master yarn-client
      shell:  cat /{{ var_env_tmp_dir }}/{{ var_file_test_spark }} | spark-shell --master yarn
      register: results
    - debug:
        var: results
    
    - name: print result word count 
      shell:  hdfs dfs -cat /{{ var_env_tmp_dir }}/sparkout/part-\*
      register: results
    - debug:
        var: results

  
    ############################################################ 
    # CLEANING
       
    # обнуление временной папки
    - name: delete enviroment /temp {{ var_env_tmp_dir }}
      ansible.builtin.file:
        path: /{{ var_env_tmp_dir }}
        state: absent    
    
    # cleaning hive table
    - name: cleaning hive table 
      shell:  beeline -u "jdbc:hive2:///{{ var_hiveserver2 }}:10000/" -e 'DROP TABLE default.smoke_test;'  
      register: results
    - debug:
        var: results    
     # отчиска временной папки hdfs
    - name: clean HDFS 
      shell: hdfs dfs -rmr /{{ var_env_tmp_dir }}
   


